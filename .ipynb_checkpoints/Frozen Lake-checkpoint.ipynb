{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f3b00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047792d",
   "metadata": {},
   "source": [
    "# Random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e99e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 100 episodes:\n",
      "Average timesteps per episode: 7.74\n",
      "Average reward per episode: 0.03\n",
      "Average time per episode: 0.0003 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluate random policy\"\"\"\n",
    "total_epochs, total_rewards = 0,0\n",
    "episodes = 100\n",
    "\n",
    "tic = time.perf_counter()\n",
    "#loop through 100 episodes\n",
    "for _ in range(episodes):\n",
    "    #set current state to starting environment\n",
    "    state = env.reset()\n",
    "    epochs = 0\n",
    "    \n",
    "    #done = reach the goal\n",
    "    done = False\n",
    "    \n",
    "    episode_reward = 0\n",
    "    #while not reach the goal\n",
    "    while not done:\n",
    "        #select a random action\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        #apply the action\n",
    "        state, reward, done, info = env.step(action)\n",
    "        \n",
    "        episode_reward += reward\n",
    "\n",
    "        #increment epochs\n",
    "        epochs += 1\n",
    "\n",
    "    #after 1 episode, sum penalties and episodes\n",
    "    total_epochs += epochs\n",
    "    total_rewards += episode_reward\n",
    "\n",
    "toc = time.perf_counter()\n",
    "average_time = (toc - tic)/episodes\n",
    "#print evaluation of agents performance\n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "print(f\"Average reward per episode: {total_rewards / episodes}\")\n",
    "print(f\"Average time per episode: {average_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc0871",
   "metadata": {},
   "source": [
    "# Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db8a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17e02",
   "metadata": {},
   "source": [
    "- S means the starting point\n",
    "- H means the hole\n",
    "- F means the frozen lake\n",
    "- G means the goal location\n",
    "- The red square indicates the current location of agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be897d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a q_table of size 16 x 4\n",
    "q_table = np.zeros((env.observation_space.n,env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0447253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameters\n",
    "lr = 0.5      \n",
    "discount = 1 \n",
    "epsilon = 0.1\n",
    "\n",
    "total_rewards = []\n",
    "for _ in range(10000):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    total_rewards.append(\"0\") #At the beginning, consider no rewards\n",
    "    while not done:\n",
    "        #Select action\n",
    "        if np.max(q_table[state]) > 0:\n",
    "            action = np.argmax(q_table[state]) # Exploit learnt values\n",
    "        else:\n",
    "            action = env.action_space.sample() # Explore action space\n",
    "        \n",
    "        #Implement the action\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        #Update q value\n",
    "        old_value = q_table[state, action]\n",
    "        next_max = np.max(q_table[new_state])\n",
    "        new_value = (1 - lr) * old_value + lr * (reward + discount * next_max)\n",
    "        q_table[state, action] = new_value #update new q value\n",
    "        \n",
    "        #Move to next state\n",
    "        state = new_state\n",
    "        \n",
    "        #If there is reward\n",
    "        if reward:\n",
    "            total_rewards[-1] = \"1\"\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd77184c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot total rewards during training\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(range(len(total_rewards)), total_rewards, color = \"#900603\")\n",
    "plt.title(\"Rewards during training with Q-learning\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "868a7df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 100 episodes:\n",
      "Average timesteps per episode: 6.0\n",
      "Average reward per episode: 1.0\n",
      "Average time per episode: 0.0003 seconds\n"
     ]
    }
   ],
   "source": [
    "'''Evaluate agent's performance'''\n",
    "episodes = 100\n",
    "\n",
    "total_epochs, total_rewards = 0,0\n",
    "tic = time.perf_counter()\n",
    "for i in range(100):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    epochs, rewards = 0,0\n",
    "    while not done: \n",
    "        if np.max(q_table[state]) < 0: #If no action with highest value, select random action\n",
    "            action = np.env.action_space.sample()\n",
    "        else:            \n",
    "            action = np.argmax(q_table[state]) #Otherwise, choose action with highest q-value\n",
    "        #Implement the action    \n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        #Move to next state\n",
    "        state = next_state\n",
    "        \n",
    "        epochs += 1\n",
    "        rewards += reward\n",
    "    #After 1 episode, update total epochs\n",
    "    total_epochs+=epochs\n",
    "    total_rewards+=rewards\n",
    "\n",
    "toc = time.perf_counter()\n",
    "average_time = (toc - tic)/episodes\n",
    "#print evaluation of agents performance\n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "print(f\"Average reward per episode: {total_rewards / episodes}\")\n",
    "print(f\"Average time per episode: {average_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8db5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
